# build
FROM registry.fedoraproject.org/fedora:rawhide AS builder

# deps + rocm toolchain
RUN dnf -y --nodocs --setopt=install_weak_deps=False install \
       make gcc cmake lld clang clang-devel compiler-rt libcurl-devel \
       rocminfo radeontop 'rocm-*' 'rocblas-*' hipblas 'hipblas-*' \
       git vim rsync sudo tar xz \
    && dnf clean all && rm -rf /var/cache/dnf/*

# llama.cpp
WORKDIR /opt/llama.cpp
RUN git clone --recursive https://github.com/ggerganov/llama.cpp.git .

# build + install
RUN git clean -xdf \
 && git pull \
 && git submodule update --recursive \
 && HIPCXX="$(hipconfig -l)/clang" HIP_PATH="$(hipconfig -R)" \
    cmake -S . -B build \
      -DGGML_HIP=ON \
      -DAMDGPU_TARGETS=gfx1151 \
      -DCMAKE_BUILD_TYPE=Release \
      -DLLAMA_HIP_UMA=ON \
 && cmake --build build --config Release -- -j$(nproc) \
 && cmake --install build --config Release

# make ld see libllama in builder too (kept same step)
RUN find /opt/llama.cpp/build -type f -name 'lib*.so*' -exec cp {} /usr/lib64/ \; \
 && ldconfig


# runtime
FROM registry.fedoraproject.org/fedora-minimal:rawhide

# runtime deps (same rocm packages; no build toolchain)
RUN microdnf -y --nodocs --setopt=install_weak_deps=0 install \
      bash ca-certificates libatomic libstdc++ libgcc \
      rocminfo radeontop 'rocm-*' 'rocblas-*' hipblas 'hipblas-*' \
  && microdnf clean all && rm -rf /var/cache/dnf/*

# bits from builder
COPY --from=builder /usr/local/ /usr/local/
COPY --from=builder /usr/include/rocwmma /usr/include/rocwmma

# ensure libllama is on the linker path
RUN echo "/usr/local/lib"  > /etc/ld.so.conf.d/local.conf \
 && echo "/usr/local/lib64" >> /etc/ld.so.conf.d/local.conf \
 && ldconfig \
 && cp -n /usr/local/lib/libllama*.so* /usr/lib64/ 2>/dev/null || true \
 && ldconfig

# helper
COPY gguf-vram-estimator.py /usr/local/bin/gguf-vram-estimator.py
RUN chmod +x /usr/local/bin/gguf-vram-estimator.py

# shell
CMD ["/bin/bash"]
