FROM fedora:rawhide

# getting Rocm7 repos
RUN <<EOF
tee /etc/yum.repos.d/rocm.repo <<REPO
[ROCm-7.0.0]
name=ROCm7.0.0
baseurl=https://repo.radeon.com/rocm/el9/7.0_beta/main
enabled=1
priority=50
gpgcheck=1
gpgkey=https://repo.radeon.com/rocm/rocm.gpg.key
REPO

tee /etc/yum.repos.d/rocm-graphics.repo <<REPO
[ROCm-7.0.0-Graphics]
name=ROCm7.0.0-Graphics
baseurl=https://repo.radeon.com/graphics/7.0_beta/rhel/9/main/x86_64/
enabled=1
priority=50
gpgcheck=1
gpgkey=https://repo.radeon.com/rocm/rocm.gpg.key
REPO

EOF

# Install build dependencies and tools
RUN dnf install -y \
       make gcc cmake lld clang clang-devel compiler-rt libcurl-devel \
       rocm rocminfo radeontop \
       git vim \
    && dnf clean all

# Set up working directory
WORKDIR /opt/llama.cpp

# Clone llama.cpp repository (with submodules)
RUN git clone --recursive https://github.com/ggerganov/llama.cpp.git .

# Build llama.cpp with HIP support
RUN git clean -xdf \
    && git pull \
    && git submodule update --recursive \
    && \
    # Configure and compile with HIP toolchain
    HIPCXX="$(hipconfig -l)/clang" HIP_PATH="$(hipconfig -R)" \
      cmake -S . -B build \
            -DGGML_HIP=ON \
            -DAMDGPU_TARGETS=gfx1151 \
            -DCMAKE_BUILD_TYPE=Release \
            -DLLAMA_HIP_UMA=ON \
    && cmake --build build --config Release -- -j$(nproc) \
    && cmake --install build --config Release

RUN find /opt/llama.cpp/build -type f -name 'lib*.so*' -exec cp {} /usr/lib64/ \; \
 && ldconfig

COPY gguf-vram-estimator.py /usr/local/bin/gguf-vram-estimator.py
RUN chmod +x /usr/local/bin/gguf-vram-estimator.py

# Ensure we are using hipblaslt
RUN printf '%s\n' \
  'export ROCBLAS_USE_HIPBLASLT=1' \
  > /etc/profile.d/rocm.sh \
  && chmod +x /etc/profile.d/rocm.sh \
  && echo 'source /etc/profile.d/rocm.sh' >> /etc/bashrc

# Default to interactive shell
CMD ["/bin/bash"]
